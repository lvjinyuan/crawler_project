

# spider目录位置


SITE = 'D:\project\crawler_project\crawler\crawler\spiders'

# 设置微博需要爬取的页数,最大设置100
NUM_PAGE = 2
# 设置新浪新闻爬取最大页数，默认全部爬取
XL_MAX_PAGE = None
# 设置人民网新闻爬取最大页数，默认全部爬取
RMW_MAX_PAGE = 1
# 设置百度贴吧爬取最大页数，默认全部爬取
TB_MAX_PAGE = 3
# 设置新华网爬取最大页数，默认全部爬取
XHW_MAX_PAGE = 2

# 设置微博搜索起始时间 格式'20190128' 默认昨天
START_TIME = None
# 设置微博搜索结束时间 默认今天
END_TIME = None

# 数据库配置
# MYSQL_HOST = 'a002.nscc-gz.cn'
# MYSQL_DBNAME = 'sa2'
# MYSQL_USER = 'test'
# MYSQL_PASSWD = 'test'
# MYSQL_PORT = 10417
#
MYSQL_HOST = 'localhost'
MYSQL_DBNAME = 'sa3'
MYSQL_USER = 'root'
MYSQL_PASSWD = 'mysql'
MYSQL_PORT = 3306

# 微博账号密码
USERNAME = '13128908028'
PASSWORD = 'aa897498632'